{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ddb478-ac39-49af-906a-2cba87e509a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### In this notebook, I will try to predict the telegrams' citation class labels based purely on doc2vec bodies representations using classical ML algorithm (LightGBM)\n",
    "\n",
    "### For the Neural Network approach see: https://colab.research.google.com/drive/16oUZ8StACapm4mHRnWmb-GGrun3Kr2EX?usp=sharing\n",
    "\n",
    "The problem is unbalanced, will use oversampling and class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2d43c94a-08aa-473c-b043-f211e0996673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold, StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, classification_report, confusion_matrix, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d82ae3ee-9245-4520-a6e4-3fbb7f6daa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c427ae44-1fbf-464b-8693-a35a6e1810e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RS = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "623179d7-605e-4315-b1a3-e09db5206b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report(y_true, y_pred):\n",
    "    print(\"Test accuracy: \", balanced_accuracy_score(y_true, y_pred))\n",
    "    print(\"Report: \")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1fb4c055-3b48-47e5-84cd-33c0b1c479a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(target_labels, n_classes: int):\n",
    "    total = len(target_labels)\n",
    "    class_weights = {}\n",
    "    for i in range(n_classes):\n",
    "        class_i_cnt = len(np.where(target_labels==i)[0])\n",
    "        class_weights[i] = (1 / class_i_cnt) * (total / n_classes)\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2df5cec3-1d16-42aa-a55e-a190a109c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"../data/labels.csv\", index_col=0)[['citation_class']]\n",
    "df_doc_vec = pd.read_csv(\"doc_vectors.csv\", index_col=0)\n",
    "df = df_labels.join(df_doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ee4e02c3-21de-441c-82be-347b6a167b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citation_class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telegram_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3_atel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.071868</td>\n",
       "      <td>-0.201624</td>\n",
       "      <td>0.271810</td>\n",
       "      <td>-0.027346</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.025864</td>\n",
       "      <td>-0.263887</td>\n",
       "      <td>0.206577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>-0.240187</td>\n",
       "      <td>0.078480</td>\n",
       "      <td>0.062145</td>\n",
       "      <td>0.063454</td>\n",
       "      <td>0.164338</td>\n",
       "      <td>0.146664</td>\n",
       "      <td>-0.192447</td>\n",
       "      <td>-0.208586</td>\n",
       "      <td>0.067344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_atel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.035786</td>\n",
       "      <td>-0.217161</td>\n",
       "      <td>0.282614</td>\n",
       "      <td>-0.033889</td>\n",
       "      <td>0.031198</td>\n",
       "      <td>-0.046244</td>\n",
       "      <td>-0.059987</td>\n",
       "      <td>-0.328853</td>\n",
       "      <td>0.239122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139342</td>\n",
       "      <td>-0.308597</td>\n",
       "      <td>0.063693</td>\n",
       "      <td>0.057740</td>\n",
       "      <td>0.121031</td>\n",
       "      <td>0.197053</td>\n",
       "      <td>0.044961</td>\n",
       "      <td>-0.165903</td>\n",
       "      <td>-0.115146</td>\n",
       "      <td>0.021687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_atel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>-0.032616</td>\n",
       "      <td>0.075140</td>\n",
       "      <td>0.022439</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>-0.061322</td>\n",
       "      <td>-0.183414</td>\n",
       "      <td>-0.094972</td>\n",
       "      <td>-0.037241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043013</td>\n",
       "      <td>0.037575</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.049404</td>\n",
       "      <td>-0.004333</td>\n",
       "      <td>0.127087</td>\n",
       "      <td>-0.182388</td>\n",
       "      <td>-0.061704</td>\n",
       "      <td>-0.121525</td>\n",
       "      <td>0.127395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_atel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.059242</td>\n",
       "      <td>-0.046478</td>\n",
       "      <td>0.014021</td>\n",
       "      <td>-0.004377</td>\n",
       "      <td>0.012646</td>\n",
       "      <td>0.059573</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>-0.012033</td>\n",
       "      <td>-0.066125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100126</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>0.012575</td>\n",
       "      <td>0.122288</td>\n",
       "      <td>-0.076159</td>\n",
       "      <td>0.130226</td>\n",
       "      <td>-0.081526</td>\n",
       "      <td>-0.087177</td>\n",
       "      <td>-0.067171</td>\n",
       "      <td>0.134256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_atel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.061535</td>\n",
       "      <td>0.041484</td>\n",
       "      <td>0.156877</td>\n",
       "      <td>0.081235</td>\n",
       "      <td>0.027755</td>\n",
       "      <td>0.061770</td>\n",
       "      <td>-0.033926</td>\n",
       "      <td>-0.095284</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097652</td>\n",
       "      <td>-0.170949</td>\n",
       "      <td>0.021982</td>\n",
       "      <td>0.089018</td>\n",
       "      <td>-0.137259</td>\n",
       "      <td>0.204253</td>\n",
       "      <td>-0.059254</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>-0.212191</td>\n",
       "      <td>0.126887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16033_atel</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.134906</td>\n",
       "      <td>-0.042763</td>\n",
       "      <td>0.117071</td>\n",
       "      <td>0.107838</td>\n",
       "      <td>0.154254</td>\n",
       "      <td>0.057849</td>\n",
       "      <td>-0.130010</td>\n",
       "      <td>-0.180962</td>\n",
       "      <td>-0.155351</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096712</td>\n",
       "      <td>-0.010427</td>\n",
       "      <td>0.036433</td>\n",
       "      <td>-0.107689</td>\n",
       "      <td>-0.104777</td>\n",
       "      <td>0.045682</td>\n",
       "      <td>-0.184436</td>\n",
       "      <td>-0.291302</td>\n",
       "      <td>-0.223877</td>\n",
       "      <td>0.116492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16034_atel</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.232072</td>\n",
       "      <td>-0.048323</td>\n",
       "      <td>0.370639</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.174632</td>\n",
       "      <td>0.103655</td>\n",
       "      <td>-0.195085</td>\n",
       "      <td>0.051462</td>\n",
       "      <td>-0.061205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134886</td>\n",
       "      <td>-0.247225</td>\n",
       "      <td>-0.183990</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>-0.115369</td>\n",
       "      <td>-0.053299</td>\n",
       "      <td>-0.091657</td>\n",
       "      <td>0.108027</td>\n",
       "      <td>-0.129829</td>\n",
       "      <td>0.142072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16035_atel</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.109719</td>\n",
       "      <td>-0.080325</td>\n",
       "      <td>0.084469</td>\n",
       "      <td>0.070288</td>\n",
       "      <td>0.178452</td>\n",
       "      <td>0.094157</td>\n",
       "      <td>-0.094856</td>\n",
       "      <td>-0.190852</td>\n",
       "      <td>-0.139286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095111</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.002844</td>\n",
       "      <td>-0.171705</td>\n",
       "      <td>-0.119383</td>\n",
       "      <td>0.038013</td>\n",
       "      <td>-0.231003</td>\n",
       "      <td>-0.288151</td>\n",
       "      <td>-0.205065</td>\n",
       "      <td>0.139147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16036_atel</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.039038</td>\n",
       "      <td>-0.100450</td>\n",
       "      <td>0.139631</td>\n",
       "      <td>-0.059305</td>\n",
       "      <td>0.245493</td>\n",
       "      <td>-0.079391</td>\n",
       "      <td>0.039994</td>\n",
       "      <td>0.110079</td>\n",
       "      <td>-0.181670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>-0.139472</td>\n",
       "      <td>-0.110495</td>\n",
       "      <td>0.077223</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>-0.022509</td>\n",
       "      <td>-0.166476</td>\n",
       "      <td>0.183221</td>\n",
       "      <td>-0.167263</td>\n",
       "      <td>0.250391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16037_atel</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.023305</td>\n",
       "      <td>-0.124804</td>\n",
       "      <td>0.165784</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>-0.052409</td>\n",
       "      <td>0.070990</td>\n",
       "      <td>-0.097568</td>\n",
       "      <td>-0.009924</td>\n",
       "      <td>-0.009867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063445</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>-0.148290</td>\n",
       "      <td>-0.019629</td>\n",
       "      <td>-0.096202</td>\n",
       "      <td>0.078240</td>\n",
       "      <td>-0.182030</td>\n",
       "      <td>-0.018399</td>\n",
       "      <td>-0.030203</td>\n",
       "      <td>0.165676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48279 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                citation_class         0         1         2         3  \\\n",
       "telegram_index                                                           \n",
       "3_atel                       0  0.071868 -0.201624  0.271810 -0.027346   \n",
       "2_atel                       0  0.035786 -0.217161  0.282614 -0.033889   \n",
       "4_atel                       0  0.006793 -0.032616  0.075140  0.022439   \n",
       "5_atel                       0  0.059242 -0.046478  0.014021 -0.004377   \n",
       "6_atel                       0  0.061535  0.041484  0.156877  0.081235   \n",
       "...                        ...       ...       ...       ...       ...   \n",
       "16033_atel                   0 -0.134906 -0.042763  0.117071  0.107838   \n",
       "16034_atel                   0 -0.232072 -0.048323  0.370639  0.093333   \n",
       "16035_atel                   0 -0.109719 -0.080325  0.084469  0.070288   \n",
       "16036_atel                   0 -0.039038 -0.100450  0.139631 -0.059305   \n",
       "16037_atel                   0 -0.023305 -0.124804  0.165784  0.107692   \n",
       "\n",
       "                       4         5         6         7         8  ...  \\\n",
       "telegram_index                                                    ...   \n",
       "3_atel          0.003459 -0.110452 -0.025864 -0.263887  0.206577  ...   \n",
       "2_atel          0.031198 -0.046244 -0.059987 -0.328853  0.239122  ...   \n",
       "4_atel          0.020744 -0.061322 -0.183414 -0.094972 -0.037241  ...   \n",
       "5_atel          0.012646  0.059573  0.001543 -0.012033 -0.066125  ...   \n",
       "6_atel          0.027755  0.061770 -0.033926 -0.095284  0.004160  ...   \n",
       "...                  ...       ...       ...       ...       ...  ...   \n",
       "16033_atel      0.154254  0.057849 -0.130010 -0.180962 -0.155351  ...   \n",
       "16034_atel      0.174632  0.103655 -0.195085  0.051462 -0.061205  ...   \n",
       "16035_atel      0.178452  0.094157 -0.094856 -0.190852 -0.139286  ...   \n",
       "16036_atel      0.245493 -0.079391  0.039994  0.110079 -0.181670  ...   \n",
       "16037_atel     -0.052409  0.070990 -0.097568 -0.009924 -0.009867  ...   \n",
       "\n",
       "                     246       247       248       249       250       251  \\\n",
       "telegram_index                                                               \n",
       "3_atel          0.011202 -0.240187  0.078480  0.062145  0.063454  0.164338   \n",
       "2_atel          0.139342 -0.308597  0.063693  0.057740  0.121031  0.197053   \n",
       "4_atel         -0.043013  0.037575  0.002611  0.049404 -0.004333  0.127087   \n",
       "5_atel         -0.100126  0.050133  0.012575  0.122288 -0.076159  0.130226   \n",
       "6_atel         -0.097652 -0.170949  0.021982  0.089018 -0.137259  0.204253   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "16033_atel     -0.096712 -0.010427  0.036433 -0.107689 -0.104777  0.045682   \n",
       "16034_atel     -0.134886 -0.247225 -0.183990  0.009600 -0.115369 -0.053299   \n",
       "16035_atel     -0.095111  0.003520 -0.002844 -0.171705 -0.119383  0.038013   \n",
       "16036_atel      0.016377 -0.139472 -0.110495  0.077223  0.006346 -0.022509   \n",
       "16037_atel     -0.063445  0.000621 -0.148290 -0.019629 -0.096202  0.078240   \n",
       "\n",
       "                     252       253       254       255  \n",
       "telegram_index                                          \n",
       "3_atel          0.146664 -0.192447 -0.208586  0.067344  \n",
       "2_atel          0.044961 -0.165903 -0.115146  0.021687  \n",
       "4_atel         -0.182388 -0.061704 -0.121525  0.127395  \n",
       "5_atel         -0.081526 -0.087177 -0.067171  0.134256  \n",
       "6_atel         -0.059254  0.035186 -0.212191  0.126887  \n",
       "...                  ...       ...       ...       ...  \n",
       "16033_atel     -0.184436 -0.291302 -0.223877  0.116492  \n",
       "16034_atel     -0.091657  0.108027 -0.129829  0.142072  \n",
       "16035_atel     -0.231003 -0.288151 -0.205065  0.139147  \n",
       "16036_atel     -0.166476  0.183221 -0.167263  0.250391  \n",
       "16037_atel     -0.182030 -0.018399 -0.030203  0.165676  \n",
       "\n",
       "[48279 rows x 257 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f2dd5305-39f0-4d93-b9a3-493de37f93aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36746\n",
       "1     9042\n",
       "2     2491\n",
       "Name: citation_class, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.citation_class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaddcae-be36-40a4-b466-db880e4e7236",
   "metadata": {},
   "source": [
    "I'll remove the last 100 records from the data, as the latest telegrams might not had a chance to get cited, and might be missleading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ca58c1ad-44f0-4d8b-b91d-7503ef70b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2558878e-63ef-4942-97e0-796cae42ab9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48179"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "70d0a33f-099a-4d4f-a589-2c2ecb474578",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.iloc[:, 1:].values, df.citation_class.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ca64e999-a1ef-4356-aed1-78cfcdcb919c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48179, 256), (48179, 1))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff291aa-7f32-4286-b31d-58e63c7059f5",
   "metadata": {},
   "source": [
    "#### random params performance check (always stratifying as the classes are very imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "858fc7af-fb2e-4f4a-a94a-49cc71ec351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ae7d86f4-3d5c-4904-8889-dc832d9c75af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier(max_depth=4, n_estimators=150, learning_rate=0.1, reg_alpha=0.1, random_state=RS)\n",
    "gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d8fefb0-4d62-4a67-a54f-8f31e4000450",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e4a25f44-1f62-4992-a7d8-28ac84177e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5853050826338905\n",
      "Test accuracy:  0.5036772314247207\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89      5500\n",
      "           1       0.58      0.25      0.35      1353\n",
      "           2       0.55      0.29      0.38       374\n",
      "\n",
      "    accuracy                           0.80      7227\n",
      "   macro avg       0.65      0.50      0.54      7227\n",
      "weighted avg       0.77      0.80      0.76      7227\n",
      "\n",
      "Confusion matrix:\n",
      "[[5320  156   24]\n",
      " [ 943  345   65]\n",
      " [ 170   96  108]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {balanced_accuracy_score(y_train, gbm.predict(X_train))}\")\n",
    "get_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f02a3-1bc8-4d1d-9287-2a529afbdac2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### add oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "20a8d3e4-7f48-4ed2-b31b-674add06c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d29e0bce-44e2-4f00-9632-1cad894f4dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e425e4a4-05a9-4694-9c1a-7be4aba2db82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier(max_depth=4, n_estimators=150, learning_rate=0.1, reg_alpha=0.1, random_state=RS)\n",
    "gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fa2cae1d-b7a9-4437-be4c-d43e24df15cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7943230553683917\n",
      "Test accuracy:  0.6532335405706998\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83      5500\n",
      "           1       0.39      0.47      0.42      1353\n",
      "           2       0.27      0.74      0.39       374\n",
      "\n",
      "    accuracy                           0.70      7227\n",
      "   macro avg       0.52      0.65      0.55      7227\n",
      "weighted avg       0.78      0.70      0.73      7227\n",
      "\n",
      "Confusion matrix:\n",
      "[[4157  936  407]\n",
      " [ 364  634  355]\n",
      " [  33   66  275]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test)\n",
    "y_pred_train = gbm.predict(X_train)\n",
    "print(f\"Train accuracy: {balanced_accuracy_score(y_train, y_pred_train)}\")\n",
    "get_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "61abad15-f183-4d5f-867c-751cdee69a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" checked><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try binary\n",
    "y_test[y_test>1] = 1\n",
    "y_train[y_train>1] = 1\n",
    "gbm = lgb.LGBMClassifier(max_depth=4, n_estimators=150, learning_rate=0.1, reg_alpha=0.1, random_state=RS)\n",
    "gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "72ac9594-92fc-4b0e-a88d-93e50c8959e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8269243109699361\n",
      "Test accuracy:  0.757174869716271\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.69      0.79      5500\n",
      "           1       0.46      0.82      0.59      1727\n",
      "\n",
      "    accuracy                           0.72      7227\n",
      "   macro avg       0.69      0.76      0.69      7227\n",
      "weighted avg       0.81      0.72      0.74      7227\n",
      "\n",
      "Confusion matrix:\n",
      "[[3813 1687]\n",
      " [ 309 1418]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test)\n",
    "y_pred_train = gbm.predict(X_train)\n",
    "print(f\"Train accuracy: {balanced_accuracy_score(y_train, y_pred_train)}\")\n",
    "get_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9e2b1-0339-414b-969f-4f0d1ae2bf7f",
   "metadata": {},
   "source": [
    "#### add class weights (thru params and manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95dec7c4-56a3-47f9-88e8-ec610848170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2a0fe905-23b3-4364-9163-35c501995eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, max_depth=4, n_estimators=150,\n",
       "               random_state=42, reg_alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, max_depth=4, n_estimators=150,\n",
       "               random_state=42, reg_alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', max_depth=4, n_estimators=150,\n",
       "               random_state=42, reg_alpha=0.1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier(max_depth=4, n_estimators=150, learning_rate=0.1, reg_alpha=0.1, class_weight='balanced', random_state=RS)\n",
    "gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "804e6403-deeb-4ce0-9690-35eeee26690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.784702428931087\n",
      "Test accuracy:  0.6510215208034433\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83      5500\n",
      "           1       0.39      0.47      0.43      1353\n",
      "           2       0.26      0.72      0.39       374\n",
      "\n",
      "    accuracy                           0.70      7227\n",
      "   macro avg       0.52      0.65      0.55      7227\n",
      "weighted avg       0.78      0.70      0.73      7227\n",
      "\n",
      "Confusion matrix:\n",
      "[[4159  944  397]\n",
      " [ 359  639  355]\n",
      " [  33   70  271]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test)\n",
    "print(f\"Train accuracy: {balanced_accuracy_score(y_train, gbm.predict(X_train))}\")\n",
    "get_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3b67b53f-da84-432d-a79a-c1b44e918ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.43798692739156914, 1: 1.780056159018695, 2: 6.449665327978581}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually\n",
    "class_weights = get_class_weights(y, 3)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2dafd8bc-e304-4da3-ab81-217cfd2271de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight={0: 0.43798692739156914, 1: 1.780056159018695,\n",
       "                             2: 6.449665327978581},\n",
       "               max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight={0: 0.43798692739156914, 1: 1.780056159018695,\n",
       "                             2: 6.449665327978581},\n",
       "               max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight={0: 0.43798692739156914, 1: 1.780056159018695,\n",
       "                             2: 6.449665327978581},\n",
       "               max_depth=4, n_estimators=150, random_state=42, reg_alpha=0.1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier(max_depth=4, n_estimators=150, learning_rate=0.1, reg_alpha=0.1, class_weight=class_weights, random_state=RS)\n",
    "gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2665ad05-fe1c-463b-a2ab-407f87fe9b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7844613033443442\n",
      "Test accuracy:  0.6510485341217048\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83      5500\n",
      "           1       0.39      0.47      0.43      1353\n",
      "           2       0.26      0.73      0.39       374\n",
      "\n",
      "    accuracy                           0.70      7227\n",
      "   macro avg       0.52      0.65      0.55      7227\n",
      "weighted avg       0.78      0.70      0.73      7227\n",
      "\n",
      "Confusion matrix:\n",
      "[[4161  923  416]\n",
      " [ 368  635  350]\n",
      " [  36   66  272]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test)\n",
    "print(f\"Train accuracy: {balanced_accuracy_score(y_train, gbm.predict(X_train))}\")\n",
    "get_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c78b3b7-fc5f-47ab-917f-eb42a00fcc77",
   "metadata": {},
   "source": [
    "#### class weights with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03274fd5-300f-453f-aaf8-45eb5f4642f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.706495117699276\n",
      "Test accuracy:  0.6242032375403967\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.44      0.61      5500\n",
      "           1       0.26      0.56      0.35      1353\n",
      "           2       0.19      0.87      0.31       374\n",
      "\n",
      "    accuracy                           0.49      7227\n",
      "   macro avg       0.47      0.62      0.42      7227\n",
      "weighted avg       0.80      0.49      0.54      7227\n",
      "\n",
      "Confusion matrix:\n",
      "[[2428 2168  904]\n",
      " [  71  757  525]\n",
      " [   5   43  326]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=RS)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "gbm = lgb.LGBMClassifier(max_depth=4, n_estimators=150, learning_rate=0.1, reg_alpha=0.1, class_weight=class_weights, random_state=RS)\n",
    "gbm.fit(X_train,y_train)\n",
    "\n",
    "y_pred = gbm.predict(X_test)\n",
    "print(f\"Train accuracy: {balanced_accuracy_score(y_train, gbm.predict(X_train))}\")\n",
    "get_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d2d7ba-2792-4be5-ab2b-028903be9f07",
   "metadata": {},
   "source": [
    "### Proceed with the model tuning. Oversampling included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c16207f4-3adc-4d88-ab81-18fc29cc831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=RS)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b0d6dc48-3512-4809-a820-5dbe073d670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 3\n",
    "kf = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d8c5d002-adb8-4546-86ff-f69b499c6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(balanced_accuracy_score, greater_is_better=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "502252f8-78a7-4ac4-9cb8-c32c409e2ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2a6c64d0-8221-4c68-be4b-ea58ad223b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [100, 250, 500, 1000],\n",
    "    'max_depth': [2, 4, 6],\n",
    "    'reg_alpha': [0.1, 1],\n",
    "    'learning_rate': [0.001, 0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "216f43bd-82d4-494c-8763-d173fa06b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSCV = RandomizedSearchCV(model, parameters, scoring=scorer, cv=kf, n_iter=333, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "91b2bcea-3e67-4b64-af30-874249d0fc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=LGBMClassifier(), n_iter=333,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [2, 4, 6],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 250, 500, 1000],\n",
       "                                        &#x27;reg_alpha&#x27;: [0.1, 1]},\n",
       "                   scoring=make_scorer(balanced_accuracy_score), verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=LGBMClassifier(), n_iter=333,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [2, 4, 6],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 250, 500, 1000],\n",
       "                                        &#x27;reg_alpha&#x27;: [0.1, 1]},\n",
       "                   scoring=make_scorer(balanced_accuracy_score), verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=LGBMClassifier(), n_iter=333,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.01, 0.1],\n",
       "                                        'max_depth': [2, 4, 6],\n",
       "                                        'n_estimators': [100, 250, 500, 1000],\n",
       "                                        'reg_alpha': [0.1, 1]},\n",
       "                   scoring=make_scorer(balanced_accuracy_score), verbose=3)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "13b22d0e-c400-4042-9c82-ebc62521d551",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=2, n_estimators=100, reg_alpha=0.1;, score=0.579 total time=   4.1s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=2, n_estimators=100, reg_alpha=0.1;, score=0.569 total time=   4.6s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=2, n_estimators=100, reg_alpha=0.1;, score=0.581 total time=   4.1s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=2, n_estimators=100, reg_alpha=1;, score=0.579 total time=   4.7s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=2, n_estimators=100, reg_alpha=1;, score=0.569 total time=   4.2s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=2, n_estimators=100, reg_alpha=1;, score=0.581 total time=   4.5s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=2, n_estimators=250, reg_alpha=0.1;, score=0.584 total time=   9.2s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=2, n_estimators=250, reg_alpha=0.1;, score=0.572 total time=   8.2s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=2, n_estimators=250, reg_alpha=0.1;, score=0.582 total time=  10.1s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=2, n_estimators=250, reg_alpha=1;, score=0.583 total time=   9.5s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=2, n_estimators=250, reg_alpha=1;, score=0.572 total time=   9.2s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=2, n_estimators=250, reg_alpha=1;, score=0.582 total time=   8.4s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=2, n_estimators=500, reg_alpha=0.1;, score=0.590 total time=  15.3s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=2, n_estimators=500, reg_alpha=0.1;, score=0.582 total time=  15.1s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=2, n_estimators=500, reg_alpha=0.1;, score=0.590 total time=  14.7s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=2, n_estimators=500, reg_alpha=1;, score=0.590 total time=  15.6s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=2, n_estimators=500, reg_alpha=1;, score=0.582 total time=  15.8s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=2, n_estimators=500, reg_alpha=1;, score=0.590 total time=  16.6s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=2, n_estimators=1000, reg_alpha=0.1;, score=0.604 total time=  31.2s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=2, n_estimators=1000, reg_alpha=0.1;, score=0.595 total time=  32.1s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=2, n_estimators=1000, reg_alpha=0.1;, score=0.602 total time=  39.8s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=2, n_estimators=1000, reg_alpha=1;, score=0.603 total time=  40.6s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=2, n_estimators=1000, reg_alpha=1;, score=0.595 total time=  40.6s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=2, n_estimators=1000, reg_alpha=1;, score=0.601 total time=  31.0s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=4, n_estimators=100, reg_alpha=0.1;, score=0.624 total time=   8.0s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=4, n_estimators=100, reg_alpha=0.1;, score=0.608 total time=   8.2s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=4, n_estimators=100, reg_alpha=0.1;, score=0.619 total time=   8.1s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=4, n_estimators=100, reg_alpha=1;, score=0.624 total time=   8.4s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=4, n_estimators=100, reg_alpha=1;, score=0.607 total time=   8.3s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=4, n_estimators=100, reg_alpha=1;, score=0.619 total time=   8.1s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=4, n_estimators=250, reg_alpha=0.1;, score=0.631 total time=  18.3s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=4, n_estimators=250, reg_alpha=0.1;, score=0.616 total time=  18.2s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=4, n_estimators=250, reg_alpha=0.1;, score=0.628 total time=  25.6s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=4, n_estimators=250, reg_alpha=1;, score=0.631 total time=  18.3s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=4, n_estimators=250, reg_alpha=1;, score=0.616 total time=  19.2s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=4, n_estimators=250, reg_alpha=1;, score=0.628 total time=  18.9s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=4, n_estimators=500, reg_alpha=0.1;, score=0.637 total time=  39.2s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=4, n_estimators=500, reg_alpha=0.1;, score=0.621 total time=  42.3s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=4, n_estimators=500, reg_alpha=0.1;, score=0.633 total time=  41.8s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=4, n_estimators=500, reg_alpha=1;, score=0.636 total time=  42.1s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=4, n_estimators=500, reg_alpha=1;, score=0.621 total time=  41.4s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=4, n_estimators=500, reg_alpha=1;, score=0.633 total time=  41.0s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=4, n_estimators=1000, reg_alpha=0.1;, score=0.647 total time= 1.5min\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=4, n_estimators=1000, reg_alpha=0.1;, score=0.630 total time= 1.4min\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=4, n_estimators=1000, reg_alpha=0.1;, score=0.640 total time= 1.3min\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=4, n_estimators=1000, reg_alpha=1;, score=0.647 total time= 1.3min\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=4, n_estimators=1000, reg_alpha=1;, score=0.630 total time= 1.3min\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=4, n_estimators=1000, reg_alpha=1;, score=0.640 total time= 1.3min\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=6, n_estimators=100, reg_alpha=0.1;, score=0.649 total time=  15.5s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=6, n_estimators=100, reg_alpha=0.1;, score=0.635 total time=  15.4s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=6, n_estimators=100, reg_alpha=0.1;, score=0.650 total time=  15.4s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=6, n_estimators=100, reg_alpha=1;, score=0.650 total time=  14.9s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=6, n_estimators=100, reg_alpha=1;, score=0.635 total time=  20.0s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=6, n_estimators=100, reg_alpha=1;, score=0.650 total time=  15.8s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=6, n_estimators=250, reg_alpha=0.1;, score=0.654 total time=  36.4s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=6, n_estimators=250, reg_alpha=0.1;, score=0.646 total time=  38.7s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=6, n_estimators=250, reg_alpha=0.1;, score=0.658 total time=  49.1s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=6, n_estimators=250, reg_alpha=1;, score=0.654 total time=  48.4s\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=6, n_estimators=250, reg_alpha=1;, score=0.646 total time=  47.8s\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=6, n_estimators=250, reg_alpha=1;, score=0.657 total time=  48.6s\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=6, n_estimators=500, reg_alpha=0.1;, score=0.666 total time= 1.9min\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=6, n_estimators=500, reg_alpha=0.1;, score=0.651 total time= 1.5min\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=6, n_estimators=500, reg_alpha=0.1;, score=0.665 total time= 1.9min\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=6, n_estimators=500, reg_alpha=1;, score=0.664 total time= 1.9min\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=6, n_estimators=500, reg_alpha=1;, score=0.651 total time= 2.0min\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=6, n_estimators=500, reg_alpha=1;, score=0.665 total time= 2.1min\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=6, n_estimators=1000, reg_alpha=0.1;, score=0.676 total time= 4.4min\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=6, n_estimators=1000, reg_alpha=0.1;, score=0.664 total time= 4.7min\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=6, n_estimators=1000, reg_alpha=0.1;, score=0.672 total time= 3.1min\n",
      "[CV 1/3] END learning_rate=0.001, max_depth=6, n_estimators=1000, reg_alpha=1;, score=0.676 total time= 2.3min\n",
      "[CV 2/3] END learning_rate=0.001, max_depth=6, n_estimators=1000, reg_alpha=1;, score=0.663 total time= 2.1min\n",
      "[CV 3/3] END learning_rate=0.001, max_depth=6, n_estimators=1000, reg_alpha=1;, score=0.672 total time= 2.1min\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=2, n_estimators=100, reg_alpha=0.1;, score=0.603 total time=   4.0s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=2, n_estimators=100, reg_alpha=0.1;, score=0.596 total time=   3.9s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=2, n_estimators=100, reg_alpha=0.1;, score=0.601 total time=   4.1s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=2, n_estimators=100, reg_alpha=1;, score=0.603 total time=   4.5s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=2, n_estimators=100, reg_alpha=1;, score=0.596 total time=   4.3s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=2, n_estimators=100, reg_alpha=1;, score=0.601 total time=   4.4s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=2, n_estimators=250, reg_alpha=0.1;, score=0.622 total time=   8.5s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=2, n_estimators=250, reg_alpha=0.1;, score=0.614 total time=   9.2s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=2, n_estimators=250, reg_alpha=0.1;, score=0.621 total time=   8.5s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=2, n_estimators=250, reg_alpha=1;, score=0.623 total time=   8.2s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=2, n_estimators=250, reg_alpha=1;, score=0.613 total time=   8.3s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=2, n_estimators=250, reg_alpha=1;, score=0.621 total time=   8.3s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=2, n_estimators=500, reg_alpha=0.1;, score=0.635 total time=  16.9s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=2, n_estimators=500, reg_alpha=0.1;, score=0.624 total time=  16.9s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=2, n_estimators=500, reg_alpha=0.1;, score=0.637 total time=  15.8s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=2, n_estimators=500, reg_alpha=1;, score=0.636 total time=  13.2s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=2, n_estimators=500, reg_alpha=1;, score=0.624 total time=  13.7s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=2, n_estimators=500, reg_alpha=1;, score=0.637 total time=  14.9s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=2, n_estimators=1000, reg_alpha=0.1;, score=0.654 total time=  28.4s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=2, n_estimators=1000, reg_alpha=0.1;, score=0.640 total time=  26.1s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=2, n_estimators=1000, reg_alpha=0.1;, score=0.656 total time=  26.4s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=2, n_estimators=1000, reg_alpha=1;, score=0.655 total time=  26.5s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=2, n_estimators=1000, reg_alpha=1;, score=0.641 total time=  26.2s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=2, n_estimators=1000, reg_alpha=1;, score=0.656 total time=  26.3s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=0.1;, score=0.647 total time=   7.9s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=0.1;, score=0.630 total time=   7.4s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=0.1;, score=0.640 total time=   7.0s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1;, score=0.647 total time=   7.6s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1;, score=0.630 total time=   7.8s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=4, n_estimators=100, reg_alpha=1;, score=0.639 total time=   8.5s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1;, score=0.669 total time=  16.9s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1;, score=0.655 total time=  17.9s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=0.1;, score=0.667 total time=  19.0s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=1;, score=0.669 total time=  17.6s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=1;, score=0.654 total time=  18.7s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=4, n_estimators=250, reg_alpha=1;, score=0.667 total time=  16.6s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=4, n_estimators=500, reg_alpha=0.1;, score=0.694 total time=  29.9s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=4, n_estimators=500, reg_alpha=0.1;, score=0.685 total time=  29.7s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=4, n_estimators=500, reg_alpha=0.1;, score=0.697 total time=  29.8s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=4, n_estimators=500, reg_alpha=1;, score=0.694 total time=  29.4s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=4, n_estimators=500, reg_alpha=1;, score=0.685 total time=  31.8s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=4, n_estimators=500, reg_alpha=1;, score=0.696 total time=  32.9s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=4, n_estimators=1000, reg_alpha=0.1;, score=0.738 total time=  57.3s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=4, n_estimators=1000, reg_alpha=0.1;, score=0.729 total time= 1.0min\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=4, n_estimators=1000, reg_alpha=0.1;, score=0.740 total time=  58.2s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=4, n_estimators=1000, reg_alpha=1;, score=0.737 total time=  55.6s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=4, n_estimators=1000, reg_alpha=1;, score=0.728 total time=  56.5s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=4, n_estimators=1000, reg_alpha=1;, score=0.739 total time=  58.9s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=6, n_estimators=100, reg_alpha=0.1;, score=0.677 total time=  12.3s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=6, n_estimators=100, reg_alpha=0.1;, score=0.663 total time=  11.6s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=6, n_estimators=100, reg_alpha=0.1;, score=0.672 total time=  12.0s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=6, n_estimators=100, reg_alpha=1;, score=0.677 total time=  12.2s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=6, n_estimators=100, reg_alpha=1;, score=0.663 total time=  11.7s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=6, n_estimators=100, reg_alpha=1;, score=0.671 total time=  12.4s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1;, score=0.712 total time=  27.8s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1;, score=0.696 total time=  28.8s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=0.1;, score=0.706 total time=  26.3s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=1;, score=0.710 total time=  27.6s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=1;, score=0.695 total time=  26.9s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=6, n_estimators=250, reg_alpha=1;, score=0.706 total time=  27.1s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=6, n_estimators=500, reg_alpha=0.1;, score=0.756 total time=  50.6s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=6, n_estimators=500, reg_alpha=0.1;, score=0.744 total time=  50.8s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=6, n_estimators=500, reg_alpha=0.1;, score=0.753 total time=  49.5s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=6, n_estimators=500, reg_alpha=1;, score=0.755 total time=  51.2s\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=6, n_estimators=500, reg_alpha=1;, score=0.742 total time=  49.9s\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=6, n_estimators=500, reg_alpha=1;, score=0.755 total time=  57.8s\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=6, n_estimators=1000, reg_alpha=0.1;, score=0.819 total time= 2.0min\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=6, n_estimators=1000, reg_alpha=0.1;, score=0.813 total time= 1.6min\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=6, n_estimators=1000, reg_alpha=0.1;, score=0.820 total time= 1.6min\n",
      "[CV 1/3] END learning_rate=0.01, max_depth=6, n_estimators=1000, reg_alpha=1;, score=0.818 total time= 1.6min\n",
      "[CV 2/3] END learning_rate=0.01, max_depth=6, n_estimators=1000, reg_alpha=1;, score=0.814 total time= 1.8min\n",
      "[CV 3/3] END learning_rate=0.01, max_depth=6, n_estimators=1000, reg_alpha=1;, score=0.822 total time= 1.7min\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=2, n_estimators=100, reg_alpha=0.1;, score=0.656 total time=   4.3s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=2, n_estimators=100, reg_alpha=0.1;, score=0.642 total time=   3.9s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=2, n_estimators=100, reg_alpha=0.1;, score=0.656 total time=   4.5s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=2, n_estimators=100, reg_alpha=1;, score=0.654 total time=   4.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=2, n_estimators=100, reg_alpha=1;, score=0.641 total time=   4.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=2, n_estimators=100, reg_alpha=1;, score=0.657 total time=   4.3s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=2, n_estimators=250, reg_alpha=0.1;, score=0.688 total time=   8.1s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=2, n_estimators=250, reg_alpha=0.1;, score=0.679 total time=   8.3s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=2, n_estimators=250, reg_alpha=0.1;, score=0.691 total time=   8.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=2, n_estimators=250, reg_alpha=1;, score=0.687 total time=   8.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=2, n_estimators=250, reg_alpha=1;, score=0.679 total time=   7.7s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=2, n_estimators=250, reg_alpha=1;, score=0.692 total time=   7.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=2, n_estimators=500, reg_alpha=0.1;, score=0.725 total time=  13.6s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=2, n_estimators=500, reg_alpha=0.1;, score=0.718 total time=  14.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=2, n_estimators=500, reg_alpha=0.1;, score=0.729 total time=  15.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=2, n_estimators=500, reg_alpha=1;, score=0.726 total time=  15.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=2, n_estimators=500, reg_alpha=1;, score=0.717 total time=  14.6s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=2, n_estimators=500, reg_alpha=1;, score=0.729 total time=  16.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=2, n_estimators=1000, reg_alpha=0.1;, score=0.780 total time=  32.6s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=2, n_estimators=1000, reg_alpha=0.1;, score=0.773 total time=  30.2s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=2, n_estimators=1000, reg_alpha=0.1;, score=0.780 total time=  27.2s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=2, n_estimators=1000, reg_alpha=1;, score=0.779 total time=  27.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=2, n_estimators=1000, reg_alpha=1;, score=0.772 total time=  26.7s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=2, n_estimators=1000, reg_alpha=1;, score=0.779 total time=  26.3s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1;, score=0.734 total time=   6.3s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1;, score=0.728 total time=   5.9s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=0.1;, score=0.740 total time=   5.9s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=1;, score=0.738 total time=   6.2s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=1;, score=0.729 total time=   6.1s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=4, n_estimators=100, reg_alpha=1;, score=0.739 total time=   5.9s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1;, score=0.821 total time=  13.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1;, score=0.818 total time=  13.3s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=0.1;, score=0.825 total time=  13.5s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=1;, score=0.823 total time=  13.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=1;, score=0.815 total time=  13.3s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=4, n_estimators=250, reg_alpha=1;, score=0.826 total time=  13.1s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=4, n_estimators=500, reg_alpha=0.1;, score=0.884 total time=  24.7s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=4, n_estimators=500, reg_alpha=0.1;, score=0.883 total time=  24.7s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=4, n_estimators=500, reg_alpha=0.1;, score=0.888 total time=  24.3s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=4, n_estimators=500, reg_alpha=1;, score=0.885 total time=  25.4s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=4, n_estimators=500, reg_alpha=1;, score=0.883 total time=  25.9s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=4, n_estimators=500, reg_alpha=1;, score=0.891 total time=  24.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=4, n_estimators=1000, reg_alpha=0.1;, score=0.924 total time=  46.5s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=4, n_estimators=1000, reg_alpha=0.1;, score=0.925 total time=  47.9s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=4, n_estimators=1000, reg_alpha=0.1;, score=0.930 total time=  49.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=4, n_estimators=1000, reg_alpha=1;, score=0.926 total time=  53.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=4, n_estimators=1000, reg_alpha=1;, score=0.926 total time=  53.6s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=4, n_estimators=1000, reg_alpha=1;, score=0.931 total time=  53.3s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0.1;, score=0.818 total time=  11.2s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0.1;, score=0.815 total time=  10.9s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0.1;, score=0.820 total time=  10.2s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=1;, score=0.820 total time=  10.1s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=1;, score=0.816 total time=  10.5s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=1;, score=0.821 total time=  11.4s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=6, n_estimators=250, reg_alpha=0.1;, score=0.896 total time=  25.8s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=6, n_estimators=250, reg_alpha=0.1;, score=0.899 total time=  23.3s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=6, n_estimators=250, reg_alpha=0.1;, score=0.904 total time=  23.0s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=6, n_estimators=250, reg_alpha=1;, score=0.900 total time=  23.2s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=6, n_estimators=250, reg_alpha=1;, score=0.900 total time=  22.8s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=6, n_estimators=250, reg_alpha=1;, score=0.903 total time=  22.6s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=6, n_estimators=500, reg_alpha=0.1;, score=0.934 total time=  43.2s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=6, n_estimators=500, reg_alpha=0.1;, score=0.936 total time=  44.4s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=6, n_estimators=500, reg_alpha=0.1;, score=0.939 total time=  43.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=6, n_estimators=500, reg_alpha=1;, score=0.935 total time=  44.0s\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=6, n_estimators=500, reg_alpha=1;, score=0.935 total time=  45.7s\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=6, n_estimators=500, reg_alpha=1;, score=0.937 total time=  47.7s\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=6, n_estimators=1000, reg_alpha=0.1;, score=0.949 total time= 1.6min\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=6, n_estimators=1000, reg_alpha=0.1;, score=0.950 total time= 1.6min\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=6, n_estimators=1000, reg_alpha=0.1;, score=0.953 total time= 1.4min\n",
      "[CV 1/3] END learning_rate=0.1, max_depth=6, n_estimators=1000, reg_alpha=1;, score=0.949 total time= 1.7min\n",
      "[CV 2/3] END learning_rate=0.1, max_depth=6, n_estimators=1000, reg_alpha=1;, score=0.949 total time= 1.8min\n",
      "[CV 3/3] END learning_rate=0.1, max_depth=6, n_estimators=1000, reg_alpha=1;, score=0.952 total time= 1.7min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=LGBMClassifier(), n_iter=333,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [2, 4, 6],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 250, 500, 1000],\n",
       "                                        &#x27;reg_alpha&#x27;: [0.1, 1]},\n",
       "                   scoring=make_scorer(balanced_accuracy_score), verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=LGBMClassifier(), n_iter=333,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [2, 4, 6],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 250, 500, 1000],\n",
       "                                        &#x27;reg_alpha&#x27;: [0.1, 1]},\n",
       "                   scoring=make_scorer(balanced_accuracy_score), verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=LGBMClassifier(), n_iter=333,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.01, 0.1],\n",
       "                                        'max_depth': [2, 4, 6],\n",
       "                                        'n_estimators': [100, 250, 500, 1000],\n",
       "                                        'reg_alpha': [0.1, 1]},\n",
       "                   scoring=make_scorer(balanced_accuracy_score), verbose=3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "51119124-3c6f-4e32-a71f-c6745f983b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = RSCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4a139f88-5622-4d55-93ba-402c27fc5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9995828921615811\n",
      "Test accuracy:  0.5830201005753373\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      5500\n",
      "           1       0.49      0.42      0.45      1353\n",
      "           2       0.53      0.42      0.47       374\n",
      "\n",
      "    accuracy                           0.79      7227\n",
      "   macro avg       0.63      0.58      0.60      7227\n",
      "weighted avg       0.78      0.79      0.78      7227\n",
      "\n",
      "Confusion matrix:\n",
      "[[4998  452   50]\n",
      " [ 695  569   89]\n",
      " [  87  130  157]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_estimator.predict(X_test)\n",
    "print(f\"Train accuracy: {balanced_accuracy_score(y_train, best_estimator.predict(X_train))}\")\n",
    "get_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "722a8aa8-b126-4e4a-b7c1-67d6b50eaaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_alpha': 0.1, 'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSCV.best_params_  # that's a huge overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "84193e30-e425-42e4-b37f-7721126600e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMClassifier(**{'reg_alpha': 1, 'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1, 'reg_lambda': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2382fcd4-fc9d-4b45-a601-2cb704ec62f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9994973315793413\n",
      "Test accuracy:  0.5874105763517529\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      5500\n",
      "           1       0.50      0.42      0.46      1353\n",
      "           2       0.52      0.43      0.47       374\n",
      "\n",
      "    accuracy                           0.79      7227\n",
      "   macro avg       0.63      0.59      0.61      7227\n",
      "weighted avg       0.78      0.79      0.79      7227\n",
      "\n",
      "Confusion matrix:\n",
      "[[5006  440   54]\n",
      " [ 688  574   91]\n",
      " [  88  126  160]]\n"
     ]
    }
   ],
   "source": [
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbm.predict(X_test)\n",
    "print(f\"Train accuracy: {balanced_accuracy_score(y_train, gbm.predict(X_train))}\")\n",
    "get_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29713365-44f8-4d30-b07a-beeacff6a4ef",
   "metadata": {},
   "source": [
    "### Merge 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "438a5844-43a9-43c9-a842-434129a48c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary = (y_pred > 0).astype(int)\n",
    "y_test_binary = (y_test > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6cef85d7-eb2f-4ce8-9d90-4f90aee5df0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7351876085697742\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      5500\n",
      "           1       0.67      0.56      0.61      1727\n",
      "\n",
      "    accuracy                           0.83      7227\n",
      "   macro avg       0.77      0.74      0.75      7227\n",
      "weighted avg       0.82      0.83      0.82      7227\n",
      "\n",
      "Confusion matrix:\n",
      "[[5017  483]\n",
      " [ 763  964]]\n"
     ]
    }
   ],
   "source": [
    "get_report(y_test_binary, y_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41020d5-1be0-4431-aff2-3e4662835e06",
   "metadata": {},
   "source": [
    "### check for the feature importances for the possible overfit reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a6dfdea4-a592-4cfd-a4cd-3a691d247eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "feature_imp = pd.DataFrame({'Value': gbm.feature_importances_, 'Feature': df.iloc[:, 1:].columns})\n",
    "\n",
    "plt.figure(figsize=(40, 20))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n",
    "                                                        ascending=False)[0:15])\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39e04e-c868-4b66-9daa-ed97e9011fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
