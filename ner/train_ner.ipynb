{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec79a81-881c-4094-a460-ab8cdc01826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install prodigy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a32764-d26e-4b24-b2e4-e912b7a478e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-16 16:13:36.277600: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl#egg=en_core_web_sm==3.1.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c46f004c-31ef-43d8-b8ac-73e029f74208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-19 12:30:35.800005: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "\u001b[38;5;2m✔ Removed 'astro_ner_data' from database SQLite\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy drop astro_ner_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dbb7fe7-7944-44f0-a43e-8284f32800b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-19 12:31:11.697407: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[38;5;2m✔ Created dataset 'astro_ner_data' in database SQLite\u001b[0m\n",
      "\u001b[38;5;2m✔ Imported 46725 annotations to 'astro_ner_data' (session\n",
      "2023-05-19_12-31-16) in database SQLite\u001b[0m\n",
      "Found and keeping existing \"answer\" in 0 examples\n"
     ]
    }
   ],
   "source": [
    "!prodigy db-in astro_ner_data training_data/prodigy_train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf8f49bc-c47b-4622-b0c3-9af2f61203ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-19 12:31:39.778478: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "========================= Generating Prodigy config =========================\u001b[0m\n",
      "\u001b[38;5;4mℹ Auto-generating config with spaCy\u001b[0m\n",
      "\u001b[38;5;4mℹ Using config from base model\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated training config\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-05-19 12:31:48,243] [INFO] Set up nlp object from config\n",
      "Components: ner\n",
      "Merging training and evaluation data for 1 components\n",
      "  - [ner] Training: 39717 | Evaluation: 7008 (15% split)\n",
      "Training: 39690 | Evaluation: 7007\n",
      "Labels: ner (2)\n",
      "[2023-05-19 12:31:54,111] [INFO] Pipeline: ['ner', 'tok2vec']\n",
      "[2023-05-19 12:31:54,111] [INFO] Resuming training for: ['ner', 'tok2vec']\n",
      "[2023-05-19 12:31:54,122] [INFO] Created vocabulary\n",
      "[2023-05-19 12:31:55,103] [INFO] Added vectors: ../word2vec/floret-256/\n",
      "[2023-05-19 12:31:55,889] [INFO] Finished initializing nlp object\n",
      "[2023-05-19 12:31:55,889] [INFO] Initialized pipeline components: []\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "Components: ner\n",
      "Merging training and evaluation data for 1 components\n",
      "  - [ner] Training: 39717 | Evaluation: 7008 (15% split)\n",
      "Training: 39690 | Evaluation: 7007\n",
      "Labels: ner (2)\n",
      "\u001b[38;5;4mℹ Pipeline: ['ner', 'tok2vec']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS NER  LOSS TOK2VEC  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  --------  ------------  ------  ------  ------  ------\n",
      "  0       0     56.77          0.00    0.00    0.00    0.00    0.00\n",
      "  0     200   1493.43          0.00   78.52   89.13   70.16    0.79\n",
      "  0     400    679.04          0.00   86.49   94.79   79.53    0.86\n",
      "  0     600    423.28          0.00   92.70   96.74   88.99    0.93\n",
      "  0     800    300.48          0.00   93.55   95.72   91.48    0.94\n",
      "  0    1000    172.38          0.00   93.48   95.96   91.11    0.93\n",
      "  0    1200    230.21          0.00   95.31   96.55   94.09    0.95\n",
      "  0    1400    176.87          0.00   95.05   95.61   94.50    0.95\n",
      "  0    1600    179.28          0.00   95.64   97.96   93.43    0.96\n",
      "  0    1800    190.81          0.00   96.04   97.03   95.08    0.96\n",
      "  0    2000    160.28          0.00   96.32   97.73   94.95    0.96\n",
      "  0    2200    116.38          0.00   96.30   96.95   95.67    0.96\n",
      "  0    2400    118.23          0.00   96.46   97.47   95.47    0.96\n",
      "  0    2600    162.45          0.00   96.38   97.06   95.70    0.96\n",
      "  0    2800    125.85          0.00   96.69   97.91   95.51    0.97\n",
      "  0    3000    121.58          0.00   95.66   97.38   94.00    0.96\n",
      "  0    3200    154.73          0.00   96.74   97.41   96.07    0.97\n",
      "  0    3400     93.25          0.00   97.20   97.96   96.44    0.97\n",
      "  0    3600    114.86          0.00   97.20   98.31   96.12    0.97\n",
      "  0    3800    112.23          0.00   97.26   98.26   96.27    0.97\n",
      "  0    4000    151.34          0.00   97.19   97.67   96.71    0.97\n",
      "  0    4200    127.10          0.00   97.25   98.35   96.16    0.97\n",
      "  0    4400    137.08          0.00   97.03   97.97   96.11    0.97\n",
      "  0    4600    150.32          0.00   97.66   98.70   96.64    0.98\n",
      "  0    4800    235.78          0.00   97.59   98.16   97.02    0.98\n",
      "  0    5000    288.68          0.00   97.59   98.81   96.41    0.98\n",
      "  0    5200    213.56          0.00   98.08   98.32   97.84    0.98\n",
      "  0    5400    232.57          0.00   98.09   97.97   98.21    0.98\n",
      "  0    5600    199.04          0.00   97.95   98.95   96.96    0.98\n",
      "  0    5800    177.98          0.00   98.31   98.32   98.30    0.98\n",
      "  0    6000    191.87          0.00   98.34   98.54   98.14    0.98\n",
      "  0    6200    148.42          0.00   98.33   98.54   98.12    0.98\n",
      "  0    6400    166.13          0.00   98.66   98.79   98.53    0.99\n",
      "  0    6600    210.72          0.00   98.56   98.94   98.19    0.99\n",
      "  0    6800    107.99          0.00   98.55   98.81   98.29    0.99\n",
      "  0    7000    221.83          0.00   98.66   99.02   98.30    0.99\n",
      "  0    7200    138.93          0.00   98.52   98.93   98.10    0.99\n",
      "  0    7400    140.13          0.00   98.59   98.92   98.28    0.99\n",
      "  0    7600    183.52          0.00   98.35   98.35   98.36    0.98\n",
      "  0    7800    141.62          0.00   98.42   98.18   98.68    0.98\n",
      "  0    8000    150.84          0.00   98.73   99.24   98.21    0.99\n",
      "  0    8200    146.97          0.00   98.77   99.32   98.22    0.99\n",
      "  0    8400    157.42          0.00   98.82   99.08   98.57    0.99\n",
      "  0    8600    167.44          0.00   98.79   98.82   98.76    0.99\n",
      "  0    8800    105.77          0.00   98.86   99.01   98.71    0.99\n",
      "  0    9000    180.29          0.00   98.68   99.31   98.06    0.99\n",
      "  0    9200    230.56          0.00   98.84   98.93   98.74    0.99\n",
      "  0    9400    115.75          0.00   98.80   98.88   98.72    0.99\n",
      "  0    9600    111.86          0.00   98.86   99.31   98.40    0.99\n",
      "  0    9800    167.10          0.00   98.75   98.61   98.89    0.99\n",
      "  0   10000    137.25          0.00   98.85   98.83   98.87    0.99\n",
      "  0   10200    148.00          0.00   98.93   99.21   98.65    0.99\n",
      "  0   10400     73.11          0.00   98.75   98.82   98.69    0.99\n",
      "  0   10600    109.19          0.00   98.78   98.83   98.72    0.99\n",
      "  0   10800    123.23          0.00   97.77   98.11   97.43    0.98\n",
      "  0   11000    143.25          0.00   98.20   98.58   97.83    0.98\n",
      "  0   11200    119.49          0.00   98.96   99.17   98.75    0.99\n",
      "  0   11400     98.22          0.00   98.90   99.19   98.62    0.99\n",
      "  0   11600    160.95          0.00   98.97   99.38   98.58    0.99\n",
      "  0   11800    144.26          0.00   98.54   98.59   98.48    0.99\n",
      "  0   12000     98.98          0.00   98.97   99.27   98.68    0.99\n",
      "  0   12200    120.79          0.00   98.87   99.09   98.64    0.99\n",
      "  0   12400    137.03          0.00   98.76   98.59   98.94    0.99\n",
      "  0   12600    159.79          0.00   98.98   99.28   98.68    0.99\n",
      "  0   12800     96.97          0.00   98.84   99.42   98.27    0.99\n",
      "  0   13000    123.97          0.00   98.77   98.95   98.59    0.99\n",
      "  0   13200    116.13          0.00   98.80   98.67   98.92    0.99\n",
      "  0   13400    100.45          0.00   98.85   98.86   98.85    0.99\n",
      "  0   13600    233.81          0.00   98.87   99.04   98.71    0.99\n",
      "  0   13800    141.56          0.00   98.95   99.00   98.90    0.99\n",
      "  0   14000    100.53          0.00   98.95   99.28   98.62    0.99\n",
      "  0   14200    104.28          0.00   98.69   98.48   98.91    0.99\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "astro_ner/model-last\n"
     ]
    }
   ],
   "source": [
    "!prodigy train astro_ner --ner astro_ner_data --base-model ../word2vec/floret-256/ --eval-split 0.15 --training.max_steps=30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5882482-21e2-4e0d-b10d-09a49126837d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
