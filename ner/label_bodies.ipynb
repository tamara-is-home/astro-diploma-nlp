{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "817246af-b848-4e7d-a038-8da0433a7f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 12:30:46.682010: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import spacy \n",
    "from spacy.displacy import render\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92e9a7f4-7bc3-4ce5-a0c0-6d6723a828f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl#egg=en_core_web_sm==3.1.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3616bb8-d0d0-423f-954b-c6f08b4cb2dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db2cf12-0891-44ee-8eef-c8b6748268d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/assembled.csv\", index_col=0)\n",
    "clean_bodies = pd.read_csv(\"../word2vec/clean_bodies.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52987f69-7203-4501-bd76-d734d26525f8",
   "metadata": {},
   "source": [
    "### Load both the provided and the found entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf5425b0-1d3c-45e6-80d3-8f79a42784f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_patterns = []  # single token patterns\n",
    "multi_patterns = []  # multi-token patterns\n",
    "\n",
    "with open(\"entities_collection/patterns_provided.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        json_line = json.loads(line)\n",
    "        this_pattern = json_line[\"pattern\"][0]\n",
    "        if \"TEXT\" in this_pattern.keys():\n",
    "            multi_patterns.append(json_line)\n",
    "        elif len(this_pattern['lower'].split(' ')) > 1:\n",
    "            this_pattern_text = this_pattern['lower']\n",
    "            this_pattern_regex = {\"label\": json_line['label'], \"pattern\": [{\"TEXT\": {\"REGEX\": fr\"\\b({this_pattern_text})\\b\"}}]}\n",
    "            multi_patterns.append(this_pattern_regex)\n",
    "        else:\n",
    "            token_patterns.append(json_line)\n",
    "            \n",
    "with open(\"entities_collection/patterns_found.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        json_line = json.loads(line)\n",
    "        this_pattern = json_line[\"pattern\"][0]\n",
    "        if \"TEXT\" in this_pattern.keys():\n",
    "            multi_patterns.append(json_line)\n",
    "        elif len(this_pattern['lower'].split(' ')) > 1:\n",
    "            this_pattern_text = this_pattern['lower']\n",
    "            this_pattern_regex = {\"label\": json_line['label'], \"pattern\": [{\"TEXT\": {\"REGEX\": fr\"\\b({this_pattern_text})\\b\"}}]}\n",
    "            multi_patterns.append(this_pattern_regex)\n",
    "        else:\n",
    "            token_patterns.append(json_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95cb8c4-9b04-41f6-ac4d-c187733a8135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3188, 3240)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multi_patterns), len(token_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "295d0488-a76a-4a17-bcce-48cdd37302f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'label': 'SOURCE', 'pattern': [{'lower': 'grb200613a'}]},\n",
       "  {'label': 'SOURCE', 'pattern': [{'lower': 'grb200622a'}]},\n",
       "  {'label': 'SOURCE', 'pattern': [{'lower': 'grb200623a'}]},\n",
       "  {'label': 'SOURCE', 'pattern': [{'lower': 'grb200623b'}]},\n",
       "  {'label': 'SOURCE', 'pattern': [{'lower': 'grb200625a'}]}],)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_patterns[:5], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a01b3af-aa44-42e9-a3c0-cc7ea12eec16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'TELESCOPE', 'pattern': [{'lower': 'lamost'}]},\n",
       " {'label': 'TELESCOPE', 'pattern': [{'lower': 'spitzer'}]},\n",
       " {'label': 'TELESCOPE', 'pattern': [{'lower': 'aristarchos'}]},\n",
       " {'label': 'TELESCOPE', 'pattern': [{'lower': 'planck'}]},\n",
       " {'label': 'TELESCOPE', 'pattern': [{'lower': '74\\xa0inch'}]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_patterns[-10:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0835a0c3-9309-4d44-860f-f247fc3f5ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'SOURCE',\n",
       "  'pattern': [{'TEXT': {'REGEX': '\\\\b(IceCube|IC|GRB|FRB|PKS|Mrk|HAWC|MAXI|GW)([ -]?)([0-9\\\\.\\\\-\\\\+]{2,}[A-Z]?)\\\\b'}}]},\n",
       " {'label': 'SOURCE',\n",
       "  'pattern': [{'TEXT': {'REGEX': '\\\\b(AT) *?([0-9]{4}[a-z]{3})\\\\b'}}]},\n",
       " {'label': 'SOURCE',\n",
       "  'pattern': [{'TEXT': {'REGEX': '\\\\b(ZTF)([0-9]{2}[a-z]{7})\\\\\\\\b'}}]},\n",
       " {'label': 'SOURCE',\n",
       "  'pattern': [{'TEXT': {'REGEX': '\\\\b(irregular variable)\\\\b'}}]},\n",
       " {'label': 'SOURCE',\n",
       "  'pattern': [{'TEXT': {'REGEX': '\\\\b(sx phe variable)\\\\b'}}]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_patterns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2aff061-8cb9-41bb-a31d-e4a37b67b22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'TELESCOPE',\n",
       "  'pattern': [{'TEXT': {'REGEX': '\\\\b(telescopio amici osservatorio astrofisico di arcetri)\\\\b'}}]},\n",
       " {'label': 'TELESCOPE',\n",
       "  'pattern': [{'TEXT': {'REGEX': '\\\\b(griffith observatory)\\\\b'}}]},\n",
       " {'label': 'TELESCOPE',\n",
       "  'pattern': [{'TEXT': {'REGEX': '\\\\b(gran ecuatorial observatorio astronómico nacional)\\\\b'}}]},\n",
       " {'label': 'TELESCOPE',\n",
       "  'pattern': [{'TEXT': {'REGEX': '\\\\b(himalayan chandra telescope)\\\\b'}}]},\n",
       " {'label': 'TELESCOPE',\n",
       "  'pattern': [{'TEXT': {'REGEX': '\\\\b(steward observatory 60\" cassegrain telescope)\\\\b'}}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_patterns[-10:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c05af2-61cb-4091-9fc3-2b5d1ea4a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single-token patterns can be loaded to spacy directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b1a3633-89f7-4d7b-a076-4b015696556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_patterns_lower_temp = multi_patterns[3:]\n",
    "# the first 3 multi-patterns are not in lower-case\n",
    "multi_patterns_temp = ast.literal_eval(str(multi_patterns[:3]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2969ec44-4bdf-4dec-9322-25bcd6e31368",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 gamma\n",
      "-1 gamma\n",
      "-1 gamma\n",
      "-1 gamma\n",
      "-1 gamma\n",
      "-1 gamma\n",
      "-1 gamma\n"
     ]
    }
   ],
   "source": [
    "# will throw all the gamma-related stuff from the TELESCOPE labels, they are creating lots of noise\n",
    "multi_patterns_lower = []\n",
    "for pat in multi_patterns_lower_temp:\n",
    "    if pat['label'] == 'TELESCOPE':\n",
    "        regex = pat['pattern'][0]['TEXT']['REGEX']\n",
    "        if 'gamma' in str(regex):\n",
    "            print('-1 gamma')\n",
    "            continue\n",
    "    multi_patterns_lower.append(pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40e9f957-e801-420e-8631-df6356624f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_patterns_lower += multi_patterns_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79c612ed-6aeb-494c-b5ae-43c75dc2c280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3181"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multi_patterns_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eb9b37-7a59-4677-bd16-0b0c8c38e566",
   "metadata": {},
   "source": [
    "### For each telegram body perform a search for an entity and get a corresponding span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4974b78a-8304-48b8-801c-22de0f59e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner_span(body):\n",
    "    res = list()\n",
    "    doc = nlp(body)\n",
    "    \n",
    "    # token re matches\n",
    "    for ent in doc.ents:\n",
    "        res.append((ent.start_char, ent.end_char, ent.label_))\n",
    "    \n",
    "    # full text re matches LOWER CASE (cleaned bodies)\n",
    "    for pattern in multi_patterns_lower:\n",
    "        try:\n",
    "            label = pattern['label']\n",
    "\n",
    "            for match in re.finditer(pattern['pattern'][0]['TEXT']['REGEX'], doc.text.lower()):\n",
    "                start, end = match.span()\n",
    "                span = doc.char_span(start, end)\n",
    "                # This is a Span object or None if match doesn't map to valid token sequence\n",
    "                if span is not None:\n",
    "                    span.label_ = label\n",
    "                    res.append((span.start_char, span.end_char, span.label_))\n",
    "        except:\n",
    "            pass  # broken RE patterns may happen\n",
    "                \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32101b71-ad27-403d-816e-5e6c02aeb574",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35eca954-1a5e-4021-b58a-0a1bc77145d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove default NER and replace with single-token entity ruler for labeling\n",
    "nlp.remove_pipe(\"ner\")\n",
    "nlp.add_pipe(\"entity_ruler\").add_patterns(token_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1366d-5020-41ec-bdda-c3d7ae0aef1a",
   "metadata": {},
   "source": [
    "#### Test entity ruler single-token NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fb60a34-80e0-42c5-b877-42fead978a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_body = df.body[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34c8637a-e87e-413f-85eb-9c4f787c87d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    GRB980109\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SOURCE</span>\n",
       "</mark>\n",
       " field was observed by the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    OGLE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TELESCOPE</span>\n",
       "</mark>\n",
       " collaboration with the 1.3-m Warsaw telescope at the Las Campanas Observatory, Chile on Jan. 10.06, 10.18, 11.05, 12.05 and 16.05, 1998. Ten 900 sec I-band exposures were collected. The field size was 14.2 by 14.2 arcmins covering almost entire error box. None fading or variable stellar-like object was detected up to detection limit of I ~ 21 mag and variability threshold of 0.4 mag.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render(nlp(test_body), style=\"ent\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd7d4d-4381-4d0a-8497-95e16876eb7f",
   "metadata": {},
   "source": [
    "#### Find all spans including the multi-token ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88913e19-f717-42b0-b282-c35c3e317830",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ner_spans'] = df.body.apply(get_ner_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642e796-f747-4709-9438-f6eefe50870f",
   "metadata": {},
   "source": [
    "### Convert the spans to the NER training data format (both spacy binary and prodigy jsonl)\n",
    "(the overlapping spans are fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cccc2795-3fa5-4500-8316-17ebf237dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')\n",
    "db = DocBin()\n",
    "\n",
    "for i, r in df.iterrows():\n",
    "    text = r.body\n",
    "    annotations = r.ner_spans\n",
    "    if annotations:\n",
    "        doc = nlp(text)\n",
    "        ents = []\n",
    "        for start, end, label in annotations:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            ents.append(span)\n",
    "        doc.ents = filter_spans(ents)\n",
    "        db.add(doc)\n",
    "\n",
    "        \n",
    "db.to_disk(\"training_data/spacy_train.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28228297-fcc8-412a-ab93-59a74b257749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and also save it to prodigy so we can read and correct labels later if needed\n",
    "\n",
    "doc_bin = DocBin().from_disk(\"training_data/spacy_train.spacy\")  \n",
    "examples = []  # examples in Prodigy format\n",
    "for doc in doc_bin.get_docs(nlp.vocab):\n",
    "    spans = [{\"start\": ent.start_char, \"end\": ent.end_char, \"label\": ent.label_} for ent in doc.ents]\n",
    "    examples.append({\"text\": doc.text, \"spans\": spans})\n",
    "    \n",
    "with open('training_data/prodigy_train.jsonl', 'w') as f:\n",
    "    for line in examples:\n",
    "        f.write(f\"{json.dumps(line)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2807cac1-3687-4586-9dfb-d4a8fb12cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ruler-based found entities for the future comparison\n",
    "df[['ner_spans']].to_csv(\"rb_ents.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06cde5e3-ab5e-4ef8-86b2-9dee312fc7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ner_spans    [(10, 16, TELESCOPE)]\n",
       "Name: 2432_atel, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.iloc[12355][['ner_spans']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
